---
title: "Breast cancer"
author: "Mariana Pasqualini"
date: "10/15/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(knitr.kable.NA = "", fig.align='center', fig.dim=c(8, 8))
```


## Motivação do classificador de câncer de mama

O objetivo desse notebook é aplicar técnicas de classificação aos dados do dataset _Breast cancer Wisconsin_, disponível [aqui](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29). O interesse nesse dataset vem do _outubro rosa_, mês de conscientização para informar, alertar e previnir o câncer de mama. De acordo com o Instituto Nacional de Câncer (INCA), em 2019 foram estimados 59700 novos casos da doença no Brasil.

Quanto antes, melhor!

Esse estudo é **apenas** para fins didáticos e de aprendizado, que não necessariamente reflete a realidade ou uma opinião médica. 

## Pacotes

```{r packages, message=FALSE, warning=FALSE}
library(tidyverse)
library(janitor)
library(GGally)
library(caret)
library(printr)
library(corrplot)
library(factoextra)
library(pROC)

set.seed(889)

source("analysis.r")
```


## Explorando os dados: Correlações e separabilidade das classes {.tabset}

### Mean

```{r mean-pairs, echo=FALSE, warning=FALSE, message=FALSE}
pairs[[1]]
```

É possível ver rapidamente que algumas variáveis estão correlacionadas fortemente entre si. 

Algumas variáveis apresentam correlação positiva quase perfeita (muito próximo de 1), como

- **radius_mean** e **perimeter_mean** (0.998)

- **radius_mean** e **area_mean** (0.987) 

- **perimeter_area** e **area_mean** (0.987)

Outras variáveis também apresentam uma correlação forte (acima de 0.5), como 

- **concavity_mean** e **compactness_mean** (0.883)

- **concave.points_mean** e **concavity_mean** (0.921)

- **concave.points_mean** e **perimeter_mean** (0.851)

Quanto à separabilidade dos dados, observando os histogramas, parece que as variáveis **radius_mean**, **perimeter_mean**, **area_mean** e **concavity_mean** ajudam a melhor identificar as populações _benigno_ e _maligno_, mas ainda assim vemos sobreposições e nenhuma variável parece separar perfeitamente essas classes.

### Standard Error

```{r se-pairs, echo=FALSE, warning=FALSE, message=FALSE}
pairs[[2]]
```

As correlações do erro padrão dessas variáveis são, de maneira geral, um pouco mais baixas, mas ainda sim temos correlações fortes nas mesmas variáveis da média. 

Quanto à separabilidade das classes, as variáveis parecem não ajudar a identificar as duas populações.

### Worst 

```{r worst-pairs, echo=FALSE, warning=FALSE, message=FALSE}
pairs[[3]]
```

Os scatterplots dessas variáveis, que são as médias dos maiores valores, também são bem parecidas com as observadas para as médias.

Por meio das variáveis **concave.points_worst**, **radius_worst** e **perimeter_worst** parecem ser as que mais ajudam separar as classes do diagnóstico.

## {-}

***

Quando uma variável tem correlação perfeita, sabendo o valor da variável X, conseguimos prever o de Y. Com isso, podemos escrever X em função de Y (ou vice-versa). E observamos nas matrizes acima que algumas variáveis têm correlação bem alta.

Trabalhar com dados altamente correlacionados: 

 - Não acrescenta informação da variabilidade dos dados
 - Os modelos podem levar mais tempo que o necessário para serem ajustados
 
 Para ajudar nesse problema, vamos recorrer à técnicas de redução de dimensionalidade.
 
 
## PCA: Reduzindo a dimensão

Análise de componentes principais é uma técnica de fatorização de matriz em que é possível explicar (parte da) a variabilidade dos dados por meio de combinações lineares não correlacionadas dos dados originais. De maneira geral, a ideia de fatorar uma matriz é escrever uma matriz "complicada" no produto de duas matrizes "mais simples".

Vamos definir as componentes principais por meio de operações matriciais, para conhecer todo o processo. 

1. Estimando a matriz de correlação:

O primeiro passo é estimar a matriz de correlação dos nossos dados. Na verdade, nessa etapa usa-se a matriz de covariâncias, mas um problema que pode surgir é que algumas variância são maiores que outras, e em casos muito discrepantes isso distorce as componentes principais. Para evitar isso, o procedimento é: padronizar a matriz de covariâncias e estimar as componentes a partir dessa matriz padronizada. Mas isso é o mesmo que usar a matriz de correlação e por isso vou seguir por ela.

```{r cor-matrix}

upper <- cor_matrix
upper[upper.tri(cor_matrix)] <- NA 

knitr::kable(upper[1:5, 1:5],  caption = "Matriz de correlação: 5 primeiras linhas/colunas")
```

2. Obtendo os autovalores: 

```{r eigenvalues, collapse=TRUE}
eig$values

plot(eig$values)
abline(h = 1)
```

Para estimar o número de componentes principais ideal, um critério prático é observar os autovalores maiores ou iguais a 1, pois dessa forma as combinações lineares explicam a variância de uma variável original (padronizada) do dataset. Observando o scree-plot acima, é **k = 6** é o número de componentes principais adequados para explicar a estrutura da variância dos dados.

3. Obtendo os autovetores e escrevendo a 1ª componente principal:


Observando os autovetores associados aos seis autovalores identificados (apenas as 6 primeiras linhas de 30)

```{r eigenvectors, echo=FALSE, warning=FALSE, message=FALSE}

head(as.data.frame(eig$vectors[,1:6]))


```


Olhando um pouco para a teoria, a j-ésima componente principal é dada por:

$$
Ŷ_j = ê_{j1}X_{1} + ê_{j2}X_{2} + ... + ê_{jp}X_{p}
$$

E podemos escrever, para os dados do dataset em questão, a primeira componente principal da seguinte forma:

$$
Ŷ_1 = -0.2189\text{radius_mean} -0.1037\text{texture_mean} - 0.227\text{perimeter_mean} + ... - 0.132\text{fractal_dimension_worst}
$$

E assim em diante...

Mas como visualizações são mais interessantes, vamos construir gráficos!

#### Visualizando as componentes principais

Bom, como a função *fviz_pca_biplot* do pacote *factoextra* faz um gráfico apropriado a partir de um objeto da classe PCA, vou utilizar a função *princomp* (do stats, que faz parte do R base) para criar esse objeto. Essa função foi escolhida porque ela usa o **teorema da decomposição espectral**, que é a abordagem teórica utilizada na descrição acima. Caso a abordagem fosse **decomposição em valores singulares** (SVD), a função apropriada seria a *prcomp* (também do *stats*).

```{r pca-object}

pca <- princomp(data_processed[,-1], cor = TRUE, scores = TRUE)

fviz_pca_biplot(pca, col.ind = data_processed$diagnosis, col="black",
                palette = "Dark2", geom = "point", repel=TRUE,
                legend.title="Diagnóstico", addEllipses = TRUE) +
  theme(axis.line = element_line(colour = "black"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) 
```

A primeira componente explica 44.3% da variância dos dados. É possível observar que existem variáveis correlacionadas negativamente, como **smoothness_se** e **radius_mean**, justamente os vetores mais distantes entre si. Também vemos que há ali um agrupamento das classes Benigno/Maligno.

Como o PCA foi utilizado para reduzir a dimensionalidade dos dados, os scores das 6 primeiras dimensões serão utilizados para ajustar o modelo de classificação.

## Classificando

Organizando os dados que serão utilizados no modelo:

```{r score}
data_scores <- 
  bind_cols(data_processed$diagnosis, as.data.frame(pca$scores[,1:6])) %>% 
  clean_names() %>% 
  rename(diagnosis = x1)
```

Dividindo os dados em conjuntos de treino e teste (70/30):

```{r train-test, message=FALSE}
train <- data_scores %>% sample_frac(.7)
test <- data_scores %>% anti_join(train)
```

### Modelo 01: Regressão logística

#### Ajustando o modelo

```{r logistic-1}
logistic_model1 <- glm(diagnosis ~ ., family = binomial, data = train)
summary(logistic_model1)
```

A variável comp_6 parece **não** contribuir significativamente para classificarmos o diagnóstico (utilizando $\alpha = 0.05$). Um novo modelo pode ser ajustado removendo essa variável, já que variáveis irrelevantes podem deteriorar a taxa de erro do modelo.

```{r logistic-2}
logistic_model2 <- glm(diagnosis ~ comp_1 + comp_2 + comp_3 + comp_4 + comp_5, 
                       family = binomial, data = train)

summary(logistic_model2)
```

#### E como fica no conjunto de teste?

Queremos prever _novas_ observações, então vamos lá:

```{r predict}
pred <-
  predict(logistic_model2, test, type = "response") %>% 
  as.data.frame() %>% 
  rename(., "prob" = ".") %>% 
  bind_cols(test) %>% 
  mutate(predicted = as.factor(ifelse(prob > 0.5, "Malignant", "Benign")))

```

As probabilidades são dadas na forma $P(Y = 1 | X)$, e olhando para a dummy definida como 1

```{r}
contrasts(data_scores$diagnosis)
```

olhamos para os valores como sendo a probabilidade do tumor ser maligno.

#### Avaliando a acurácia do modelo

```{r conf-matrix, collapse=TRUE}
cmat <- conf_mat(table(pred$predicted, pred$diagnosis))
autoplot(cmat, type = "heatmap")

pred %>% metrics(diagnosis, predicted)
```

A acurácia do modelo é de 99.4% e o coeficiente de Kappa 98.7%, que nos indica uma concordância entre o predito e os valores verdadeiros. É importante lembrar que a acurácia é uma métrica que deve ser usada com cuidado, pois ela pode não representar bem a situação. 

Na área da saúde, as medidas mais utilizadas são a especificidade e a sensibilidade, comuns em testes diagnósticos. Em termos práticos, a sensibilidade avalia a capacidade do classificador detectar o tumor maligno quando ele está presente. Já a especificidade nos dá a probabilidade de um teste dar negativo (no caso, benigno) quando, de fato, não há doença. A sensibilidade do classificador é de 98,2% e a especifidade 100%.

Quando estamos em um cenário de classificação, uma forma de checarmos a taxa de erro associada ao conjunto de teste é estimada da seguinte forma:


$Media(I(y_{0} \neq \hat{y_0}))$


Ou seja, é a média de uma variável indicadora que assume 1 quando a classe predita é igual a classe verdadeira e 0, caso contrário. Queremos o menor valor possível para essa média. Assim, considerando o problema, temos:

```{r}
mean(pred$diagnosis != pred$predicted)
```

Ou seja, o modelo de regressão logística previu incorretamente, em média, apenas 0.6% das vezes.

ROC e AUC:

```{r roc-auc, collapse=TRUE}
predr <- prediction(pred$prob, pred$diagnosis)
perf <- performance(predr, "tpr", "fpr")
plot(perf)


auc <- performance(predr, measure = 'auc') 
auc <- unlist(slot(auc, 'y.values'))
print(paste('AUC on Test', auc))
```


## Referências

https://www.inca.gov.br/publicacoes/livros/situacao-do-cancer-de-mama-no-brasil-sintese-de-dados-dos-sistemas-de-informacao